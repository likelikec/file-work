{
 "cells": [
  {
   "cell_type": "code",
   "id": "f378eccc-ee8e-468c-aabd-4cef5a4cae75",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-11T07:05:45.925358Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, classification_report,\n",
    "    confusion_matrix, precision_recall_curve\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 22\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset, DataLoader, TensorDataset\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torchvision'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffd13cd-10c0-41d5-8157-ed64f19781a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78f693a-03ed-4ca5-91ff-37b2e0251db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 B   COM_RAT    Cyclic         D      Dcy*       DIT  \\\n",
      "B         1.000000 -0.079649 -0.077862  0.949534  0.072115 -0.021094   \n",
      "COM_RAT  -0.079649  1.000000  0.371491 -0.136029  0.194926 -0.185669   \n",
      "Cyclic   -0.077862  0.371491  1.000000 -0.159031  0.471428 -0.048793   \n",
      "D         0.949534 -0.136029 -0.159031  1.000000  0.064286  0.016784   \n",
      "Dcy*      0.072115  0.194926  0.471428  0.064286  1.000000  0.304261   \n",
      "DIT      -0.021094 -0.185669 -0.048793  0.016784  0.304261  1.000000   \n",
      "DPT*     -0.049545  0.245961  0.725074 -0.112133  0.149629 -0.194484   \n",
      "E         0.958448 -0.046733 -0.022641  0.850430  0.042574 -0.037622   \n",
      "INNER     0.204053 -0.195664 -0.298160  0.286254  0.159500  0.573214   \n",
      "LCOM      0.329428  0.063240 -0.162739  0.310297 -0.067734 -0.124741   \n",
      "Level    -0.151357  0.359927  0.758563 -0.249851  0.627880 -0.009210   \n",
      "LOC       0.845559 -0.027157 -0.161820  0.837003  0.100741  0.011395   \n",
      "N         0.903764 -0.113874 -0.149923  0.886971  0.089542  0.018400   \n",
      "NCLOC     0.894196 -0.126473 -0.186748  0.883800  0.096175  0.051437   \n",
      "NOAC      0.803069 -0.073738 -0.106559  0.760374  0.052138 -0.018257   \n",
      "NOC      -0.074807  0.129398  0.237103 -0.119754  0.224733 -0.025525   \n",
      "NOIC      0.082166 -0.133833 -0.199801  0.153866  0.261988  0.611079   \n",
      "OCmax     0.568465 -0.209725 -0.317073  0.649633  0.109793  0.119469   \n",
      "PDcy      0.334681 -0.177841 -0.201724  0.450767  0.350983  0.329888   \n",
      "PDpt      0.220558  0.062264  0.122971  0.244028  0.019754 -0.104359   \n",
      "STAT      0.898659 -0.128799 -0.169469  0.886087  0.100424  0.045149   \n",
      "SUB       0.067098  0.323451 -0.013598  0.054021  0.031197 -0.052717   \n",
      "TCOM_RAT  0.008986  0.135495 -0.058287  0.013578 -0.037511 -0.062751   \n",
      "V         0.916185 -0.103419 -0.149737  0.883059  0.102443  0.031819   \n",
      "WMC       0.909385 -0.115931 -0.165633  0.879147  0.052870  0.012287   \n",
      "\n",
      "              DPT*         E     INNER      LCOM  ...       NOC      NOIC  \\\n",
      "B        -0.049545  0.958448  0.204053  0.329428  ... -0.074807  0.082166   \n",
      "COM_RAT   0.245961 -0.046733 -0.195664  0.063240  ...  0.129398 -0.133833   \n",
      "Cyclic    0.725074 -0.022641 -0.298160 -0.162739  ...  0.237103 -0.199801   \n",
      "D        -0.112133  0.850430  0.286254  0.310297  ... -0.119754  0.153866   \n",
      "Dcy*      0.149629  0.042574  0.159500 -0.067734  ...  0.224733  0.261988   \n",
      "DIT      -0.194484 -0.037622  0.573214 -0.124741  ... -0.025525  0.611079   \n",
      "DPT*      1.000000 -0.005412 -0.259636 -0.134162  ...  0.105197 -0.214187   \n",
      "E        -0.005412  1.000000  0.128874  0.276054  ... -0.042171  0.026278   \n",
      "INNER    -0.259636  0.128874  1.000000 -0.006918  ... -0.211704  0.518415   \n",
      "LCOM     -0.134162  0.276054 -0.006918  1.000000  ... -0.020326 -0.003157   \n",
      "Level     0.391659 -0.081856 -0.293543 -0.152856  ...  0.418090 -0.201480   \n",
      "LOC      -0.072483  0.740276  0.331781  0.399819  ... -0.140678  0.139952   \n",
      "N        -0.082376  0.812374  0.309200  0.393757  ... -0.141055  0.144114   \n",
      "NCLOC    -0.098736  0.800875  0.380027  0.392795  ... -0.160192  0.166500   \n",
      "NOAC     -0.041096  0.755889  0.283268  0.343985  ... -0.120495  0.058108   \n",
      "NOC       0.105197 -0.042171 -0.211704 -0.020326  ...  1.000000 -0.136141   \n",
      "NOIC     -0.214187  0.026278  0.518415 -0.003157  ... -0.136141  1.000000   \n",
      "OCmax    -0.178717  0.419704  0.496293  0.250098  ... -0.220593  0.279697   \n",
      "PDcy     -0.184829  0.197536  0.579507  0.094050  ... -0.108434  0.404991   \n",
      "PDpt      0.188048  0.141124  0.006734  0.048416  ...  0.061639 -0.067525   \n",
      "STAT     -0.090443  0.809973  0.351878  0.385855  ... -0.149723  0.162412   \n",
      "SUB       0.121416  0.038952  0.074545  0.060026  ...  0.017772 -0.015558   \n",
      "TCOM_RAT -0.020352  0.000658  0.013596 -0.046252  ... -0.018058 -0.001908   \n",
      "V        -0.082891  0.839468  0.319406  0.392473  ... -0.134617  0.143511   \n",
      "WMC      -0.083952  0.844088  0.321776  0.410390  ... -0.142774  0.115912   \n",
      "\n",
      "             OCmax      PDcy      PDpt      STAT       SUB  TCOM_RAT  \\\n",
      "B         0.568465  0.334681  0.220558  0.898659  0.067098  0.008986   \n",
      "COM_RAT  -0.209725 -0.177841  0.062264 -0.128799  0.323451  0.135495   \n",
      "Cyclic   -0.317073 -0.201724  0.122971 -0.169469 -0.013598 -0.058287   \n",
      "D         0.649633  0.450767  0.244028  0.886087  0.054021  0.013578   \n",
      "Dcy*      0.109793  0.350983  0.019754  0.100424  0.031197 -0.037511   \n",
      "DIT       0.119469  0.329888 -0.104359  0.045149 -0.052717 -0.062751   \n",
      "DPT*     -0.178717 -0.184829  0.188048 -0.090443  0.121416 -0.020352   \n",
      "E         0.419704  0.197536  0.141124  0.809973  0.038952  0.000658   \n",
      "INNER     0.496293  0.579507  0.006734  0.351878  0.074545  0.013596   \n",
      "LCOM      0.250098  0.094050  0.048416  0.385855  0.060026 -0.046252   \n",
      "Level    -0.376446 -0.251436  0.038900 -0.238685 -0.050098 -0.057542   \n",
      "LOC       0.759334  0.462964  0.158303  0.941706  0.289763  0.040349   \n",
      "N         0.719227  0.442146  0.103656  0.969964  0.113372  0.001224   \n",
      "NCLOC     0.783207  0.489730  0.103564  0.990887  0.139930  0.008928   \n",
      "NOAC      0.607474  0.369002  0.080612  0.874391  0.197118  0.008182   \n",
      "NOC      -0.220593 -0.108434  0.061639 -0.149723  0.017772 -0.018058   \n",
      "NOIC      0.279697  0.404991 -0.067525  0.162412 -0.015558 -0.001908   \n",
      "OCmax     1.000000  0.674522  0.032662  0.760779  0.154517  0.022240   \n",
      "PDcy      0.674522  1.000000  0.090054  0.474147  0.089126 -0.011874   \n",
      "PDpt      0.032662  0.090054  1.000000  0.077819  0.112181  0.053061   \n",
      "STAT      0.760779  0.474147  0.077819  1.000000  0.111988  0.006219   \n",
      "SUB       0.154517  0.089126  0.112181  0.111988  1.000000  0.110505   \n",
      "TCOM_RAT  0.022240 -0.011874  0.053061  0.006219  0.110505  1.000000   \n",
      "V         0.728293  0.439019  0.081512  0.988788  0.120010  0.001540   \n",
      "WMC       0.705579  0.402482  0.071976  0.980470  0.144014  0.007497   \n",
      "\n",
      "                 V       WMC  \n",
      "B         0.916185  0.909385  \n",
      "COM_RAT  -0.103419 -0.115931  \n",
      "Cyclic   -0.149737 -0.165633  \n",
      "D         0.883059  0.879147  \n",
      "Dcy*      0.102443  0.052870  \n",
      "DIT       0.031819  0.012287  \n",
      "DPT*     -0.082891 -0.083952  \n",
      "E         0.839468  0.844088  \n",
      "INNER     0.319406  0.321776  \n",
      "LCOM      0.392473  0.410390  \n",
      "Level    -0.217376 -0.241427  \n",
      "LOC       0.944854  0.944452  \n",
      "N         0.978070  0.963989  \n",
      "NCLOC     0.988800  0.981496  \n",
      "NOAC      0.867851  0.886096  \n",
      "NOC      -0.134617 -0.142774  \n",
      "NOIC      0.143511  0.115912  \n",
      "OCmax     0.728293  0.705579  \n",
      "PDcy      0.439019  0.402482  \n",
      "PDpt      0.081512  0.071976  \n",
      "STAT      0.988788  0.980470  \n",
      "SUB       0.120010  0.144014  \n",
      "TCOM_RAT  0.001540  0.007497  \n",
      "V         1.000000  0.983428  \n",
      "WMC       0.983428  1.000000  \n",
      "\n",
      "[25 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./project_train.xlsx')\n",
    "df = df.fillna(0)\n",
    "corr = df[FEATURE_COLUMNS].corr()\n",
    "print(corr)\n",
    "corr.to_excel('./train_corr.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4bb286ec-7d6f-464a-abbe-012bd66cd29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['testart', 'CC', 'MC', 'BC', 'LC', 'mio', 'CC-1', 'MC-1', 'BC-1',\n",
      "       'LC-1', '1适合LLM', 'metrics', 'class', 'B', 'COM_RAT', 'Cyclic', 'D',\n",
      "       'Dcy*', 'DIT', 'DPT*', 'E', 'Inner', 'LCOM', 'Level', 'LOC', 'N',\n",
      "       'NCLOC', 'NOAC', 'NOC', 'NOIC', 'OCmax', 'PDcy', 'PDpt', 'STAT', 'SUB',\n",
      "       'TCOM_RAT', 'V', 'WMC', 'CBO', 'CLOC', 'Command', 'CONS', 'CSA', 'CSO',\n",
      "       'CSOA', 'Dcy', 'DPT', 'INNER', 'jf', 'JLOC', 'Jm', 'Level*', 'MPC', 'n',\n",
      "       'NAAC', 'NAIC', 'NOOC', 'NTP', 'OCavg', 'OPavg', 'OSavg', 'OSmax',\n",
      "       'Query', 'RFC', 'TODO'],\n",
      "      dtype='object')\n",
      "Index([' lang', 'cli', 'csv', 'datafaker', 'gson', 'ruler'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./train-3.0.xlsx')\n",
    "print(df.columns)\n",
    "_cat = df['metrics'].astype('category').cat\n",
    "print(_cat.categories)\n",
    "# print(_cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72e99093-a6fb-48ea-99b3-872bad7d7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'CC'\n",
    "df[key] = df[key].str.split('%', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c8179f34-3171-4525-a84d-8e7e4f0dfd5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([' lang', 'cli', 'csv', 'datafaker', 'gson', 'jfreechart', 'ruler'], dtype='object')\n",
      "NaN:                        testart   CC     MC     BC     LC  \\\n",
      "1                ChartFactory  1.0  0.071  0.021  0.037   \n",
      "4             ChartMouseEvent  1.0  0.750    NaN  0.857   \n",
      "8                  ChartUtils  1.0  0.071  0.000  0.108   \n",
      "20         AbstractAnnotation  1.0  0.571  0.500  0.622   \n",
      "21       AbstractXYAnnotation  1.0  1.000  0.500  0.759   \n",
      "...                       ...  ...    ...    ...    ...   \n",
      "990               JsonElement  1.0  0.364  0.375  0.429   \n",
      "999   LongSerializationPolicy  1.0  0.667  0.000  0.455   \n",
      "1000           ToNumberPolicy  1.0  0.700  0.000  0.417   \n",
      "1001              TypeAdapter  1.0  0.273  0.000  0.115   \n",
      "1016          UnsafeAllocator  0.0  0.000  0.000  0.000   \n",
      "\n",
      "                          evo  CC-1   MC-1   BC-1   LC-1  ...  NAIC  NOOC  \\\n",
      "1                ChartFactory   1.0  1.000  0.921  0.997  ...     0     0   \n",
      "4             ChartMouseEvent   1.0  1.000  1.000  1.000  ...     1     0   \n",
      "8                  ChartUtils   1.0  0.143  0.125  0.217  ...     0     0   \n",
      "20         AbstractAnnotation   1.0  0.786  0.722  0.778  ...     0     3   \n",
      "21       AbstractXYAnnotation   1.0  1.000  0.929  0.971  ...     2     3   \n",
      "...                       ...   ...    ...    ...    ...  ...   ...   ...   \n",
      "990               JsonElement   1.0  1.000  0.875  0.971  ...    91     0   \n",
      "999   LongSerializationPolicy   1.0  1.000  0.750  0.909  ...    21     0   \n",
      "1000           ToNumberPolicy   1.0  0.600  0.000  0.375  ...    47     0   \n",
      "1001              TypeAdapter   1.0  1.000  1.000  0.885  ...    62     1   \n",
      "1016          UnsafeAllocator   0.4  0.500  1.000  0.385  ...    71     0   \n",
      "\n",
      "           NTP     OCavg     OPavg      OSavg  OSmax  Query  RFC        TODO  \n",
      "1     0.000000  2.592593  5.648148  10.333333   40.0     53  187    0.000000  \n",
      "4     0.000000  1.000000  0.750000   1.750000    4.0      3    5    0.000000  \n",
      "8     0.000000  1.111111  4.259259   3.000000   21.0      4   56    0.000000  \n",
      "20    0.000000  1.642857  0.642857   2.642857   10.0      6   25    0.000000  \n",
      "21    0.000000  1.777778  1.600000   3.444444   12.0      5   19    0.000000  \n",
      "...        ...       ...       ...        ...    ...    ...  ...         ...  \n",
      "990   1.181818  2.000000  1.590909   7.000000    3.0     33   35  791.836912  \n",
      "999   2.000000  2.000000  3.000000   3.000000    1.0      3    6   86.485790  \n",
      "1000  1.250000  2.000000  3.750000   9.000000    3.0      2   15  348.389232  \n",
      "1001  1.200000  2.000000  2.700000   5.000000    3.0     19   27  562.620964  \n",
      "1016  1.166667  2.000000  4.833333   3.000000    1.0     12   29  714.875200  \n",
      "\n",
      "[125 rows x 65 columns]\n",
      "[3.89701636e+00 1.56488946e+00 1.27282480e-01 2.89807507e+01\n",
      " 7.92620361e+01 9.89499519e+01 1.93358999e+00 1.69249278e+02\n",
      " 8.65983549e+05 1.34744947e-01 2.34263715e+00 4.88498556e+01\n",
      " 1.26561116e+02 2.88067372e+02 1.07564966e+02 8.07410972e+00\n",
      " 6.67564966e+00 3.55033686e+01 4.97374083e+00 2.48893167e+00\n",
      " 4.81713186e+00 5.75649663e+01 6.56603579e-01 8.79932097e-02\n",
      " 1.96597920e+03 2.29634264e+01 1.54793070e+01 2.13763234e+01\n",
      " 3.14821944e+00 1.42059673e+00 1.17410972e+01 7.10529355e+01\n",
      " 8.27940327e+01 5.53705486e+00 1.04119346e+01 2.28470849e+00\n",
      " 4.71110042e+00 1.04420460e+01 5.02511717e-02 4.27487969e+01\n",
      " 9.41645813e+01 5.67112608e+01 3.65062560e+00 3.22743022e+01\n",
      " 1.39557267e+00 6.12151097e-01 2.37715300e+00 1.86910295e+00\n",
      " 5.91678592e+00 1.52030799e+01 1.31828681e+01 3.72550529e+01\n",
      " 4.63319745e+02]\n",
      "[2.64868215e+00 2.38950863e+01 3.01511310e-02 2.53418635e+03\n",
      " 1.92028056e+04 1.00968098e+04 1.25353004e+00 4.13711150e+04\n",
      " 3.07962788e+13 4.99649382e-01 7.45334088e+00 5.42151932e+03\n",
      " 6.91923213e+04 3.53848363e+05 4.84816510e+04 4.11820302e+02\n",
      " 2.60729253e+02 9.60356664e+03 4.57548439e+01 7.16036835e+00\n",
      " 3.46345092e+01 1.73795990e+04 1.00273552e+01 5.92382954e-01\n",
      " 2.52504266e+07 2.75434130e+03 6.66184124e+02 7.36576117e+03\n",
      " 7.87326027e+01 1.45639964e+00 5.45344904e+02 1.56616151e+04\n",
      " 2.17350182e+04 5.72033911e+01 5.41064189e+02 7.97099768e+00\n",
      " 3.22951212e+02 6.39574163e+03 4.53853816e-02 1.01667675e+04\n",
      " 7.09773367e+04 6.46381268e+03 5.02253870e+01 7.76049550e+03\n",
      " 5.45757424e+00 9.46530060e-01 7.56198081e+00 6.86366728e+00\n",
      " 7.54383387e+01 5.94223436e+02 3.79958860e+02 4.17954130e+03\n",
      " 5.40709352e+06]\n"
     ]
    }
   ],
   "source": [
    "FEATURE_COLUMNS = [\n",
    "    # 'CC', 'MC', 'BC', 'LC', 'CC-1', 'MC-1', 'BC-1', 'LC-1', \n",
    "    'mertics', 'B', 'COM_RAT', 'Cyclic', 'D',\n",
    "   'Dcy*', 'DIT', 'DPT*', 'E', 'Inner', 'LCOM', 'Level', 'LOC', 'N',\n",
    "   'NCLOC', 'NOAC', 'NOC', 'NOIC', 'OCmax', 'PDcy', 'PDpt', 'STAT', 'SUB',\n",
    "   'TCOM_RAT', 'V', 'WMC', 'CBO', 'CLOC', 'Command', 'CONS', 'CSA', 'CSO',\n",
    "   'CSOA', 'Dcy', 'DPT', 'INNER', 'jf', 'JLOC', 'Jm', 'Level*', 'MPC', 'n',\n",
    "   'NAAC', 'NAIC', 'NOOC', 'NTP', 'OCavg', 'OPavg', 'OSavg', 'OSmax',\n",
    "   'Query', 'RFC', 'TODO'\n",
    "]\n",
    "# FEATURE_COLUMNS = [\n",
    "#     \"B\",\"COM_RAT\",\"Cyclic\",\"D\",\"Dcy*\",\"DIT\",\"DPT*\",\"E\",\"INNER\",\n",
    "#     \"LCOM\",\"Level\",\"LOC\",\"N\",\"NCLOC\",\"NOAC\",\"NOC\",\"NOIC\",\"OCmax\",\"PDcy\",\"PDpt\",\n",
    "#     \"STAT\",\"SUB\",\"TCOM_RAT\",\"V\",\"WMC\"\n",
    "# ]\n",
    "LABEL_COLUMN = \"1适合LLM\"\n",
    "\n",
    "def load_data(data_path, target_col=FEATURE_COLUMNS):\n",
    "    df = pd.read_excel(data_path)\n",
    "    for key in ['CC', 'MC', 'CC-1', 'MC-1']:\n",
    "        df[key] = pd.to_numeric(df[key].str.split('%', expand=True)[0]) / 100\n",
    "    for key in ['mertics']:\n",
    "        _cat = df[key].astype('category').cat\n",
    "        print(_cat.categories)\n",
    "        df[key] = _cat.codes\n",
    "    df_check = df.isnull().any(axis=1)\n",
    "    print('NaN: ', df[df_check])\n",
    "    df = df.fillna(-1)\n",
    "    \n",
    "    x = df[target_col].to_numpy()\n",
    "    y = df[LABEL_COLUMN].to_numpy()\n",
    "    return x, y\n",
    "\n",
    "train_x, train_y = load_data('./data.xlsx')\n",
    "\n",
    "# test_x, test_y = load_data('./project_test.xlsx')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x)\n",
    "print(scaler.mean_)\n",
    "print(scaler.var_)\n",
    "\n",
    "train_x = scaler.transform(train_x)\n",
    "# test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e49c3a3f-d646-44bf-8822-1c1997923647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_636/2730453684.py:8: ClusterWarning: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  Z = sch.linkage(distance_matrix, method='ward')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 20 16  5  8  9 16  5 12 10 16  4  4  4  4 17  6  3  1 24  4 15 21  4\n",
      "  4 13 14  2 11  6  6  6  1 13  7 18 14 15 24 24  3  2 24  7 19 23 23 23\n",
      "  3 22 22 24]\n",
      "24 [18, 27, 17, 11, 0, 16, 34, 4, 5, 9, 28, 8, 25, 26, 21, 2, 15, 35, 44, 1, 22, 49, 45, 19]\n",
      "['PDcy', 'Command', 'OCmax', 'LOC', 'B', 'NOIC', 'INNER', 'Dcy*', 'DIT', 'LCOM', 'CONS', 'Inner', 'CBO', 'CLOC', 'SUB', 'Cyclic', 'NOC', 'jf', 'NTP', 'COM_RAT', 'TCOM_RAT', 'Query', 'OCavg', 'PDpt']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./data.xlsx')\n",
    "for key in ['CC', 'MC', 'CC-1', 'MC-1']:\n",
    "    df[key] = pd.to_numeric(df[key].str.split('%', expand=True)[0]) / 100\n",
    "df_check = df.isnull().any(axis=1)\n",
    "df = df.fillna(-1)\n",
    "corr = df[FEATURE_COLUMNS].corr()\n",
    "distance_matrix = 1 - corr\n",
    "Z = sch.linkage(distance_matrix, method='ward')\n",
    "plt.figure(figsize=(10, 7))\n",
    "sch.dendrogram(Z, labels=corr.columns)\n",
    "plt.show()\n",
    "max_d = 1.5\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "print(clusters)\n",
    "\n",
    "_ids_list = []\n",
    "_names_list = []\n",
    "for _idx in range(max(clusters)):\n",
    "    _ids = np.where(clusters == _idx+1)[0][0]\n",
    "    _ids_list.append(_ids)\n",
    "    _names_list.append(corr.columns[_ids])\n",
    "print(len(_ids_list), _ids_list)\n",
    "print(_names_list)\n",
    "train_x = train_x[:, _ids_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "93a384a1-050b-4e73-8442-6014acbf882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1039, 4)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=4)\n",
    "train_x = pca.fit_transform(train_x)\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b0f84403-6ea1-44f8-b940-1372255139c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 53) (208, 53) (208, 53)\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(\n",
    "    train_x, train_y, test_size=0.4, random_state=42)\n",
    "\n",
    "val_x, test_x, val_y, test_y = train_test_split(\n",
    "    val_x, val_y, test_size=0.5, random_state=42)\n",
    "\n",
    "print(train_x.shape, val_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4685abb1-9708-4ecc-8bd3-713d5b73a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, labels = self.data[idx], self.labels[idx]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, labels\n",
    "\n",
    "class Block1D(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Block1D, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_channels, in_channels)\n",
    "        self.norm1 = nn.BatchNorm1d(in_channels)\n",
    "        self.layer2 = nn.Linear(in_channels, in_channels)\n",
    "        self.norm2 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.block1 = Block1D(128)\n",
    "        self.layer3 = nn.Linear(128, 64)\n",
    "        self.block2 = Block1D(64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34ca993-c3db-4164-b051-c4a4a5c473bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34130752086639404"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "228dbfaa-b11a-4efe-96ae-729e8c177022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassifier(\n",
       "  (layer1): Linear(in_features=53, out_features=128, bias=True)\n",
       "  (block1): Block1D(\n",
       "    (layer1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (block2): Block1D(\n",
       "    (layer1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "class AddNoise:\n",
    "    def __init__(self, p=0.5, noise_scale=0.05):\n",
    "        self.p = p\n",
    "        self.noise_scale = noise_scale\n",
    "    def __call__(self, x):\n",
    "        if torch.rand(1).item() < self.p:\n",
    "            x = x + torch.randn_like(x) * self.noise_scale\n",
    "        return x\n",
    "\n",
    "class RandomZero:\n",
    "    def __init__(self, feat_drop_prob=0.2):\n",
    "        self.feat_drop_prob = feat_drop_prob\n",
    "    def __call__(self, x):\n",
    "        mask = torch.rand_like(x) > self.feat_drop_prob\n",
    "        x *= mask.float()\n",
    "        return x\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "    # AddNoise(0.8, 0.02),\n",
    "    # RandomZero(0.05)\n",
    "])\n",
    "train_dataset = CustomDataset(train_x, train_y, transform)\n",
    "val_dataset = CustomDataset(val_x, val_y)\n",
    "test_dataset = CustomDataset(test_x, test_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "num_features = len(FEATURE_COLUMNS) # len(_ids_list) FEATURE_COLUMNS\n",
    "model = BinaryClassifier(input_dim=num_features)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 内置Sigmoid + 交叉熵\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "53b8788b-8042-43d6-9f46-5aac54930287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 0.3464 | Train Loss: 0.8620 | Test Loss: 0.9020 | Test Acc: 0.6731\n",
      "Epoch 2/100\n",
      "Train Loss: 0.3326 | Train Loss: 0.8636 | Test Loss: 0.7956 | Test Acc: 0.6923\n",
      "Epoch 3/100\n",
      "Train Loss: 0.3883 | Train Loss: 0.8186 | Test Loss: 0.7035 | Test Acc: 0.7019\n",
      "Epoch 4/100\n",
      "Train Loss: 0.3588 | Train Loss: 0.8555 | Test Loss: 0.6797 | Test Acc: 0.7067\n",
      "Epoch 5/100\n",
      "Train Loss: 0.3234 | Train Loss: 0.8604 | Test Loss: 0.7343 | Test Acc: 0.7019\n",
      "Epoch 6/100\n",
      "Train Loss: 0.3510 | Train Loss: 0.8507 | Test Loss: 0.7570 | Test Acc: 0.6875\n",
      "Epoch 7/100\n",
      "Train Loss: 0.3444 | Train Loss: 0.8716 | Test Loss: 0.7698 | Test Acc: 0.6971\n",
      "Epoch 8/100\n",
      "Train Loss: 0.3669 | Train Loss: 0.8491 | Test Loss: 0.7116 | Test Acc: 0.6875\n",
      "Epoch 9/100\n",
      "Train Loss: 0.3505 | Train Loss: 0.8555 | Test Loss: 0.7131 | Test Acc: 0.6923\n",
      "Epoch 10/100\n",
      "Train Loss: 0.3258 | Train Loss: 0.8764 | Test Loss: 0.6813 | Test Acc: 0.6875\n",
      "Epoch 11/100\n",
      "Train Loss: 0.3230 | Train Loss: 0.8636 | Test Loss: 0.6583 | Test Acc: 0.6971\n",
      "Epoch 12/100\n",
      "Train Loss: 0.3596 | Train Loss: 0.8411 | Test Loss: 0.7247 | Test Acc: 0.6923\n",
      "Epoch 13/100\n",
      "Train Loss: 0.2996 | Train Loss: 0.8796 | Test Loss: 0.6953 | Test Acc: 0.7019\n",
      "Epoch 14/100\n",
      "Train Loss: 0.3031 | Train Loss: 0.8716 | Test Loss: 0.7756 | Test Acc: 0.6683\n",
      "Epoch 15/100\n",
      "Train Loss: 0.3383 | Train Loss: 0.8443 | Test Loss: 0.7617 | Test Acc: 0.6779\n",
      "Epoch 16/100\n",
      "Train Loss: 0.3531 | Train Loss: 0.8684 | Test Loss: 0.7166 | Test Acc: 0.6923\n",
      "Epoch 17/100\n",
      "Train Loss: 0.3401 | Train Loss: 0.8604 | Test Loss: 0.6653 | Test Acc: 0.7019\n",
      "Epoch 18/100\n",
      "Train Loss: 0.2911 | Train Loss: 0.8860 | Test Loss: 0.6516 | Test Acc: 0.7115\n",
      "Epoch 19/100\n",
      "Train Loss: 0.3159 | Train Loss: 0.8684 | Test Loss: 0.6808 | Test Acc: 0.7067\n",
      "Epoch 20/100\n",
      "Train Loss: 0.3391 | Train Loss: 0.8571 | Test Loss: 0.6751 | Test Acc: 0.7019\n",
      "Epoch 21/100\n",
      "Train Loss: 0.3219 | Train Loss: 0.8636 | Test Loss: 0.6647 | Test Acc: 0.7115\n",
      "Epoch 22/100\n",
      "Train Loss: 0.2908 | Train Loss: 0.8684 | Test Loss: 0.7530 | Test Acc: 0.6923\n",
      "Epoch 23/100\n",
      "Train Loss: 0.3471 | Train Loss: 0.8475 | Test Loss: 0.7275 | Test Acc: 0.7115\n",
      "Epoch 24/100\n",
      "Train Loss: 0.3060 | Train Loss: 0.8604 | Test Loss: 0.7007 | Test Acc: 0.7115\n",
      "Epoch 25/100\n",
      "Train Loss: 0.3006 | Train Loss: 0.8668 | Test Loss: 0.8085 | Test Acc: 0.6635\n",
      "Epoch 26/100\n",
      "Train Loss: 0.3216 | Train Loss: 0.8748 | Test Loss: 0.7673 | Test Acc: 0.6779\n",
      "Epoch 27/100\n",
      "Train Loss: 0.3103 | Train Loss: 0.8668 | Test Loss: 0.7334 | Test Acc: 0.6731\n",
      "Epoch 28/100\n",
      "Train Loss: 0.3485 | Train Loss: 0.8459 | Test Loss: 0.7538 | Test Acc: 0.6779\n",
      "Epoch 29/100\n",
      "Train Loss: 0.3136 | Train Loss: 0.8507 | Test Loss: 0.7241 | Test Acc: 0.7067\n",
      "Epoch 30/100\n",
      "Train Loss: 0.3144 | Train Loss: 0.8604 | Test Loss: 0.7230 | Test Acc: 0.6875\n",
      "Epoch 31/100\n",
      "Train Loss: 0.3042 | Train Loss: 0.8796 | Test Loss: 0.7551 | Test Acc: 0.7212\n",
      "Epoch 32/100\n",
      "Train Loss: 0.3386 | Train Loss: 0.8571 | Test Loss: 0.7189 | Test Acc: 0.7212\n",
      "Epoch 33/100\n",
      "Train Loss: 0.3645 | Train Loss: 0.8539 | Test Loss: 0.7143 | Test Acc: 0.7115\n",
      "Epoch 34/100\n",
      "Train Loss: 0.3593 | Train Loss: 0.8491 | Test Loss: 0.6865 | Test Acc: 0.6875\n",
      "Epoch 35/100\n",
      "Train Loss: 0.3216 | Train Loss: 0.8587 | Test Loss: 0.6862 | Test Acc: 0.6875\n",
      "Epoch 36/100\n",
      "Train Loss: 0.3211 | Train Loss: 0.8684 | Test Loss: 0.6956 | Test Acc: 0.7067\n",
      "Epoch 37/100\n",
      "Train Loss: 0.3085 | Train Loss: 0.8748 | Test Loss: 0.7373 | Test Acc: 0.6923\n",
      "Epoch 38/100\n",
      "Train Loss: 0.2971 | Train Loss: 0.8764 | Test Loss: 0.7665 | Test Acc: 0.6779\n",
      "Epoch 39/100\n",
      "Train Loss: 0.3755 | Train Loss: 0.8331 | Test Loss: 0.7259 | Test Acc: 0.7067\n",
      "Epoch 40/100\n",
      "Train Loss: 0.3252 | Train Loss: 0.8491 | Test Loss: 0.7195 | Test Acc: 0.7067\n",
      "Epoch 41/100\n",
      "Train Loss: 0.3176 | Train Loss: 0.8732 | Test Loss: 0.7028 | Test Acc: 0.6971\n",
      "Epoch 42/100\n",
      "Train Loss: 0.3338 | Train Loss: 0.8587 | Test Loss: 0.7213 | Test Acc: 0.6827\n",
      "Epoch 43/100\n",
      "Train Loss: 0.2909 | Train Loss: 0.8716 | Test Loss: 0.6953 | Test Acc: 0.7163\n",
      "Epoch 44/100\n",
      "Train Loss: 0.3233 | Train Loss: 0.8604 | Test Loss: 0.7604 | Test Acc: 0.6731\n",
      "Epoch 45/100\n",
      "Train Loss: 0.3097 | Train Loss: 0.8700 | Test Loss: 0.6792 | Test Acc: 0.7115\n",
      "Epoch 46/100\n",
      "Train Loss: 0.3380 | Train Loss: 0.8604 | Test Loss: 0.7174 | Test Acc: 0.6827\n",
      "Epoch 47/100\n",
      "Train Loss: 0.3256 | Train Loss: 0.8684 | Test Loss: 0.7601 | Test Acc: 0.6971\n",
      "Epoch 48/100\n",
      "Train Loss: 0.3234 | Train Loss: 0.8604 | Test Loss: 0.7336 | Test Acc: 0.6971\n",
      "Epoch 49/100\n",
      "Train Loss: 0.3012 | Train Loss: 0.8780 | Test Loss: 0.7492 | Test Acc: 0.7067\n",
      "Epoch 50/100\n",
      "Train Loss: 0.3570 | Train Loss: 0.8539 | Test Loss: 0.7235 | Test Acc: 0.6923\n",
      "Epoch 51/100\n",
      "Train Loss: 0.3143 | Train Loss: 0.8700 | Test Loss: 0.7290 | Test Acc: 0.6827\n",
      "Epoch 52/100\n",
      "Train Loss: 0.2867 | Train Loss: 0.8780 | Test Loss: 0.7500 | Test Acc: 0.6731\n",
      "Epoch 53/100\n",
      "Train Loss: 0.3270 | Train Loss: 0.8684 | Test Loss: 0.7330 | Test Acc: 0.7019\n",
      "Epoch 54/100\n",
      "Train Loss: 0.3352 | Train Loss: 0.8716 | Test Loss: 0.7139 | Test Acc: 0.7067\n",
      "Epoch 55/100\n",
      "Train Loss: 0.3125 | Train Loss: 0.8668 | Test Loss: 0.6715 | Test Acc: 0.7163\n",
      "Epoch 56/100\n",
      "Train Loss: 0.3089 | Train Loss: 0.8828 | Test Loss: 0.7018 | Test Acc: 0.7163\n",
      "Epoch 57/100\n",
      "Train Loss: 0.3080 | Train Loss: 0.8764 | Test Loss: 0.6963 | Test Acc: 0.7067\n",
      "Epoch 58/100\n",
      "Train Loss: 0.3312 | Train Loss: 0.8587 | Test Loss: 0.7382 | Test Acc: 0.6923\n",
      "Epoch 59/100\n",
      "Train Loss: 0.3241 | Train Loss: 0.8796 | Test Loss: 0.6894 | Test Acc: 0.7163\n",
      "Epoch 60/100\n",
      "Train Loss: 0.3049 | Train Loss: 0.8700 | Test Loss: 0.7947 | Test Acc: 0.6875\n",
      "Epoch 61/100\n",
      "Train Loss: 0.3332 | Train Loss: 0.8491 | Test Loss: 0.7212 | Test Acc: 0.6923\n",
      "Epoch 62/100\n",
      "Train Loss: 0.3244 | Train Loss: 0.8716 | Test Loss: 0.7361 | Test Acc: 0.6779\n",
      "Epoch 63/100\n",
      "Train Loss: 0.3182 | Train Loss: 0.8620 | Test Loss: 0.6924 | Test Acc: 0.6875\n",
      "Epoch 64/100\n",
      "Train Loss: 0.3266 | Train Loss: 0.8427 | Test Loss: 0.6814 | Test Acc: 0.6875\n",
      "Epoch 65/100\n",
      "Train Loss: 0.3167 | Train Loss: 0.8587 | Test Loss: 0.7236 | Test Acc: 0.6875\n",
      "Epoch 66/100\n",
      "Train Loss: 0.3013 | Train Loss: 0.8668 | Test Loss: 0.7101 | Test Acc: 0.7067\n",
      "Epoch 67/100\n",
      "Train Loss: 0.2852 | Train Loss: 0.8764 | Test Loss: 0.7952 | Test Acc: 0.6827\n",
      "Epoch 68/100\n",
      "Train Loss: 0.3252 | Train Loss: 0.8636 | Test Loss: 0.7128 | Test Acc: 0.6779\n",
      "Epoch 69/100\n",
      "Train Loss: 0.2761 | Train Loss: 0.8716 | Test Loss: 0.7667 | Test Acc: 0.7019\n",
      "Epoch 70/100\n",
      "Train Loss: 0.2940 | Train Loss: 0.8844 | Test Loss: 0.7778 | Test Acc: 0.6827\n",
      "Epoch 71/100\n",
      "Train Loss: 0.3232 | Train Loss: 0.8732 | Test Loss: 0.7410 | Test Acc: 0.7212\n",
      "Epoch 72/100\n",
      "Train Loss: 0.3265 | Train Loss: 0.8796 | Test Loss: 0.7263 | Test Acc: 0.7019\n",
      "Epoch 73/100\n",
      "Train Loss: 0.2808 | Train Loss: 0.8764 | Test Loss: 0.7636 | Test Acc: 0.6923\n",
      "Epoch 74/100\n",
      "Train Loss: 0.3014 | Train Loss: 0.8684 | Test Loss: 0.7961 | Test Acc: 0.6779\n",
      "Epoch 75/100\n",
      "Train Loss: 0.3141 | Train Loss: 0.8732 | Test Loss: 0.7566 | Test Acc: 0.6971\n",
      "Epoch 76/100\n",
      "Train Loss: 0.2901 | Train Loss: 0.8700 | Test Loss: 0.7905 | Test Acc: 0.7163\n",
      "Epoch 77/100\n",
      "Train Loss: 0.3219 | Train Loss: 0.8668 | Test Loss: 0.8159 | Test Acc: 0.6971\n",
      "Epoch 78/100\n",
      "Train Loss: 0.3026 | Train Loss: 0.8636 | Test Loss: 0.8215 | Test Acc: 0.6923\n",
      "Epoch 79/100\n",
      "Train Loss: 0.3230 | Train Loss: 0.8555 | Test Loss: 0.7692 | Test Acc: 0.7067\n",
      "Epoch 80/100\n",
      "Train Loss: 0.3205 | Train Loss: 0.8604 | Test Loss: 0.7153 | Test Acc: 0.6875\n",
      "Epoch 81/100\n",
      "Train Loss: 0.3154 | Train Loss: 0.8636 | Test Loss: 0.7725 | Test Acc: 0.6635\n",
      "Epoch 82/100\n",
      "Train Loss: 0.3185 | Train Loss: 0.8780 | Test Loss: 0.7912 | Test Acc: 0.6587\n",
      "Epoch 83/100\n",
      "Train Loss: 0.3458 | Train Loss: 0.8475 | Test Loss: 0.6972 | Test Acc: 0.7115\n",
      "Epoch 84/100\n",
      "Train Loss: 0.3104 | Train Loss: 0.8604 | Test Loss: 0.7159 | Test Acc: 0.7115\n",
      "Epoch 85/100\n",
      "Train Loss: 0.3145 | Train Loss: 0.8604 | Test Loss: 0.7493 | Test Acc: 0.6875\n",
      "Epoch 86/100\n",
      "Train Loss: 0.3562 | Train Loss: 0.8507 | Test Loss: 0.7332 | Test Acc: 0.6875\n",
      "Epoch 87/100\n",
      "Train Loss: 0.2859 | Train Loss: 0.8909 | Test Loss: 0.7412 | Test Acc: 0.7019\n",
      "Epoch 88/100\n",
      "Train Loss: 0.2897 | Train Loss: 0.8796 | Test Loss: 0.7419 | Test Acc: 0.7067\n",
      "Epoch 89/100\n",
      "Train Loss: 0.3472 | Train Loss: 0.8491 | Test Loss: 0.7344 | Test Acc: 0.7019\n",
      "Epoch 90/100\n",
      "Train Loss: 0.2918 | Train Loss: 0.8684 | Test Loss: 0.7008 | Test Acc: 0.6923\n",
      "Epoch 91/100\n",
      "Train Loss: 0.3084 | Train Loss: 0.8459 | Test Loss: 0.7515 | Test Acc: 0.7115\n",
      "Epoch 92/100\n",
      "Train Loss: 0.2837 | Train Loss: 0.8812 | Test Loss: 0.7459 | Test Acc: 0.7163\n",
      "Epoch 93/100\n",
      "Train Loss: 0.3000 | Train Loss: 0.8748 | Test Loss: 0.7675 | Test Acc: 0.7019\n",
      "Epoch 94/100\n",
      "Train Loss: 0.2823 | Train Loss: 0.8732 | Test Loss: 0.7378 | Test Acc: 0.7067\n",
      "Epoch 95/100\n",
      "Train Loss: 0.2946 | Train Loss: 0.8684 | Test Loss: 0.7076 | Test Acc: 0.7067\n",
      "Epoch 96/100\n",
      "Train Loss: 0.3427 | Train Loss: 0.8652 | Test Loss: 0.6699 | Test Acc: 0.7163\n",
      "Epoch 97/100\n",
      "Train Loss: 0.2902 | Train Loss: 0.8860 | Test Loss: 0.7358 | Test Acc: 0.7260\n",
      "Epoch 98/100\n",
      "Train Loss: 0.3258 | Train Loss: 0.8555 | Test Loss: 0.7499 | Test Acc: 0.7163\n",
      "Epoch 99/100\n",
      "Train Loss: 0.3055 | Train Loss: 0.8652 | Test Loss: 0.7423 | Test Acc: 0.7308\n",
      "Epoch 100/100\n",
      "Train Loss: 0.3071 | Train Loss: 0.8668 | Test Loss: 0.7782 | Test Acc: 0.7067\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
    "        mask = torch.rand_like(inputs) < 0.3\n",
    "        _idx = torch.randperm(len(inputs))\n",
    "        _id_mask = torch.rand_like(_idx.float()) > 0.6\n",
    "        _idx[_id_mask] = torch.arange(len(inputs))[_id_mask]\n",
    "        inputs[mask] = inputs[_idx][mask]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    # 计算训练损失\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = correct / total\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_acc = correct / total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Loss: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f1643647-1c3a-4a15-ad88-f677d015bc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6132 | Test Acc: 0.7933\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "y_target = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
    "        y_target.extend(labels.view(-1).cpu().numpy())\n",
    "        outputs = model(inputs)\n",
    "        y_pred.extend(torch.nn.functional.sigmoid(outputs).view(-1).cpu().numpy())\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "y_target = np.array(y_target)\n",
    "y_pred = np.array(y_pred)\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_acc = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ea0e5238-5d31-43af-a0f5-8b816f85a9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "40912150-c4c1-42ed-ae24-0f7571ff41be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'准确率': 0.7932692307692307, '精确率': 0.7659574468085106, '召回率': 0.5294117647058824, 'F1分数': 0.6260869565217392, 'AUC': 0.8026260504201681}\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    '准确率': accuracy_score(y_target, y_pred > 0.5),\n",
    "    '精确率': precision_score(y_target, y_pred > 0.5),\n",
    "    '召回率': recall_score(y_target, y_pred > 0.5),\n",
    "    'F1分数': f1_score(y_target, y_pred > 0.5),\n",
    "    'AUC': roc_auc_score(y_target, y_pred)\n",
    "}\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "63b118fa-b836-4a76-b1ee-48b2cdf22b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[129,  11],\n",
       "       [ 32,  36]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_target, y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fc33726f-aa1b-4b72-9e1a-7e3625b2dee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.92      0.86       140\n",
      "         1.0       0.77      0.53      0.63        68\n",
      "\n",
      "    accuracy                           0.79       208\n",
      "   macro avg       0.78      0.73      0.74       208\n",
      "weighted avg       0.79      0.79      0.78       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(y_target, y_pred > 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
